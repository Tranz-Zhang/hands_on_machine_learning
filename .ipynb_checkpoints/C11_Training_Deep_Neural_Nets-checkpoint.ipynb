{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Batch Normalization with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "bn_params = {\n",
    "    'is_training': is_training,\n",
    "    'decay': 0.99, # 衰减参数，用于更新平均值参数\n",
    "    'updates_collections': None, #告知tf自动计算输入平均值\n",
    "    \n",
    "    # 对于Activition Function为ReLU或None来说，这里可以不用设置，因为这些函数支持大范围参数\n",
    "    # 其他Activition Function则需要设置Scale，因为这些核的变动范围主要为[-1，1]\n",
    "    #'scale': True, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(X, n_hidden1, scope='hidden1',\n",
    "                          normalizer_fn=batch_norm, \n",
    "                          normalizer_params=bn_params)\n",
    "hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2',\n",
    "                          normalizer_fn=batch_norm, \n",
    "                          normalizer_params=bn_params)\n",
    "logits = fully_connected(hidden2, n_outputs, activation_fn=None, scope='outputs',\n",
    "                         normalizer_fn=batch_norm, normalizer_params=bn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 避免重复传值，还可以这么写\n",
    "with tf.contrib.framework.arg_scope(\n",
    "        [fully_connected], \n",
    "        normalizer_fn=batch_norm,\n",
    "        normalizer_params=bn_params):\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope='hidden1_lite')\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2_lite')\n",
    "    logits = fully_connected(hidden2, n_outputs, scope='outputs_lite', \n",
    "                             activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/chancezhang/machine_learning/hands_on_machine_learning/tmp/C11_Model_BN.ckpt'\n",
    "n_epochs = 50\n",
    "batch_size = 50\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for it in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={is_training:True, X:X_batch, y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={is_training:False, X:X_batch, y:y_batch})\n",
    "        print('epoch', epoch, 'train_acc:', acc_train)\n",
    "    acc_test = accuracy.eval(feed_dict={is_training: False, \n",
    "                                        X: mnist.test.images,\n",
    "                                        y: mnist.test.labels})\n",
    "    print(\"Final Test Accuracy:\", acc_test)\n",
    "    saver.save(sess, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结论：\n",
    "之前的模型在mnist的准确度大概为0.979，使用BN之后准确度第一次进入0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predict\n",
    "model_path = '/Users/chancezhang/machine_learning/hands_on_machine_learning/tmp/C11_Model_BN.ckpt'\n",
    "test_idx = 1234\n",
    "test_image = mnist.test.images[test_idx]\n",
    "test_label = mnist.test.labels[test_idx]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    pred = logits.eval(feed_dict={is_training:False, X:[test_image]})\n",
    "    pred_idx = np.argmax(pred, axis=1)\n",
    "    print(\"Predict:\", pred_idx, \" Answer:\", test_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-ebd4c03b876c>:32: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "epoch 0  acc: 0.92\n",
      "epoch 1  acc: 0.94\n",
      "epoch 2  acc: 0.94\n",
      "epoch 3  acc: 0.98\n",
      "epoch 4  acc: 0.96\n",
      "epoch 5  acc: 0.94\n",
      "epoch 6  acc: 0.98\n",
      "epoch 7  acc: 0.98\n",
      "epoch 8  acc: 0.96\n",
      "epoch 9  acc: 0.98\n",
      "epoch 10  acc: 1.0\n",
      "epoch 11  acc: 0.96\n",
      "epoch 12  acc: 0.98\n",
      "epoch 13  acc: 0.98\n",
      "epoch 14  acc: 0.98\n",
      "epoch 15  acc: 1.0\n",
      "epoch 16  acc: 0.98\n",
      "epoch 17  acc: 0.98\n",
      "epoch 18  acc: 1.0\n",
      "epoch 19  acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "threshold = 1.0\n",
    "\n",
    "with tf.name_scope('graidient_clipping'):\n",
    "    # variables\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "    # dnn\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope='gc_hidden1')\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope='gc_hidden2')\n",
    "    logits = fully_connected(hidden2, n_outputs, activation_fn=None, scope='gc_outputs')\n",
    "    # loss\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='gc_loss')\n",
    "    # train\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "                 for grad, var in grads_and_vars]\n",
    "    training_op = optimizer.apply_gradients(capped_gvs)\n",
    "    # eval\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "gc_init = tf.global_variables_initializer()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\")\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    gc_init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for it in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print('epoch', epoch, ' acc:', acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
