{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 09\n",
    "Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Just like in the last exercise of Chapter 9, try adding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-226ccd005d46>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TF Graph\n",
    "n_inputs = 28 * 28\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden_1 = fully_connected(X, n_hidden_1, scope='hidden1')\n",
    "    hidden_2 = fully_connected(hidden_1, n_hidden_2, scope='hidden2')\n",
    "    outputs = fully_connected(hidden_2, n_outputs, scope='outputs', activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=outputs)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Summary for tensorboard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = \"tf_logs/c10_exercise-{}\".format(now)\n",
    "acc_summary = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_class = 500\n",
    "X_train_small = []\n",
    "y_train_small = []\n",
    "for value in np.unique(mnist.train.labels):\n",
    "    indices = np.where(mnist.train.labels == value)\n",
    "    np.random.shuffle(indices[0])\n",
    "    for image in mnist.train.images[indices[0][:n_samples_per_class]]:\n",
    "        X_train_small.append(image)\n",
    "        y_train_small.append(value)\n",
    "X_train_small = np.array(X_train_small)\n",
    "y_train_small = np.array(y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.128  Test accuracy: 0.1322\n",
      "50 Train accuracy: 0.549  Test accuracy: 0.5534\n",
      "100 Train accuracy: 0.7328  Test accuracy: 0.7412\n",
      "150 Train accuracy: 0.7882  Test accuracy: 0.7993\n",
      "200 Train accuracy: 0.8178  Test accuracy: 0.8271\n",
      "250 Train accuracy: 0.834  Test accuracy: 0.8408\n",
      "300 Train accuracy: 0.8464  Test accuracy: 0.8515\n",
      "350 Train accuracy: 0.8528  Test accuracy: 0.8583\n",
      "400 Train accuracy: 0.8592  Test accuracy: 0.8665\n",
      "450 Train accuracy: 0.8652  Test accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/Users/chancezhang/machine_learning/hands_on_machine_learning/tmp/C0_exercise/dnn_model.ckpt\"\n",
    "n_epoch = 50\n",
    "batch_size = 50\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epoch):\n",
    "        n_batchs = mnist.train.num_examples // batch_size;\n",
    "        for iteration in range(n_batchs):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size);\n",
    "            # wirte summary\n",
    "            summary_str = acc_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            step = epoch * n_batchs + iteration\n",
    "            file_writer.add_summary(summary_str, step)\n",
    "#             print(step)\n",
    "            # train\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y:mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \" Test accuracy:\", acc_test)\n",
    "    save_path = saver.save(sess, model_path)\n",
    "file_writer.flush()\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/chancezhang/machine_learning/hands_on_machine_learning/tmp/C0_exercise/dnn_model.ckpt\n",
      "Test predict: [7] Correct: 7\n"
     ]
    }
   ],
   "source": [
    "test_image = mnist.test.images[0]\n",
    "test_label = mnist.test.labels[0]\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    pred_output = outputs.eval(feed_dict={X:[test_image]})\n",
    "    y_pred = np.argmax(pred_output, axis=1)\n",
    "    print(\"Test predict:\", y_pred, \"Correct:\", test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
